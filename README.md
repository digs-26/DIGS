# DIGS #

This is the implementation repository of paper: 

Not All Synthetic Vulnerabilities Are What You Need for Training Deep Vulnerability Detectors


## Description ##

we propose DIGS, a novel diversity-guided selection approach that enables the effective use of synthetic vulnerabilities for training deep vulnerability detectors.

## Reproducibility ##
### Requirements ###
- Python==3.7.13
- torch==1.12.1
- transformers==4.25.1
- tqdm==4.62.3
- numpy==1.21.5
- scikit-learn==1.0.2
- sinularity-ce==4.2.2 (for running the detector LineVD)

### Structure ###
    |-DIGS/ "implementation for DIGS".
    |-evaluation/ "contains the code for evaluating the DIGS and baseline approaches."
    |   |-devign/ 
    |   |-linevul/
    |   |-linevd/
    |   |-VELVET/
    |-results/ "tables of experimental results."

### Usage ###
Selecting synthetic vulnerabilities with DIGS:
1. Download the original datasets and synthetic datasets by following the links in **Dataset** part. 
2. Set the database path, output path, the select ratio in `/DIGS/select.sh`.
3. Run `/DIGS/select.sh` to generate the synthetic subset indicies selected by DIGS.

Reproduce the evaluation results for vulnerability detectors:
1. We provide the data and model files mentioned in our experiments in the following links: https://zenodo.org/records/17451702 You may download the dataset from this repository, or alternatively from the original dataset link provided at the end of this readme.
2. Cd to the evaluation folder, set the synthetic subset indicies path and the dataset path in the scripts or the main file of the code, following the help of scripts `run_linevul.sh`, `run_devign.sh`, `run_linevd.sh`, `run_velvet.sh`, training and testing detectors. 
3. We provide the compared baseline approaches code file under the `/DIGS` folder. Change the method name in the `/DIGS/select.sh` to run the baseline approaches.
4. Please note that Devign, LineVD and VELVET need a long-time preprocess. We provide the preprocess scripts in each detector's folder.

### Dataset ###

#### Original vulnerabiltiy datasets ####

- Devign (a real-world vulnerable dataset collected from FFmpeg and QEMU) [1]
- ReVeal (a real-world vulnerable dataset collected from Debian and Chromium) [2]
- Big-Vul (a large scale real-world vulnerable dataset collected from CVE database) [3]

#### Synthetic vulnerability datasets ####

- VulGen (a large scale synthetic dataset generated by injecting vulnerability patterns to normal code) [4]
- VGX (an improved synthetic vulnerability dataset with manual validation and advanced localization model) [5]
- Juliet (a large manually crafted synthetic vulnerabilities designed to benchmark detection tools across) [6]

[1] Devign https://sites.google.com/view/devign

[2] ReVeal https://drive.google.com/drive/folders/1KuIYgFcvWUXheDhT--cBALsfy1I4utOy

[3] Big-Vul https://drive.google.com/file/d/1-0VhnHBp9IGh90s2wCNjeCMuy70HPl8X/view

[4] VulGen https://zenodo.org/records/10574446

[5] VGX https://zenodo.org/records/7569854

[6] Juliet https://samate.nist.gov/SARD/test-suites/112